{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor(1.)\n",
      "tensor([1., 1., 2.])\n",
      "2.0\n",
      "zeros: tensor([[0., 0.],\n",
      "        [0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([4., 1., 5., 3., 2., 1.])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.ones(3)\n",
    "print(a[0])\n",
    "print(a[1])\n",
    "print(a[2])\n",
    "\n",
    "a[2] = 2.0\n",
    "print(a)\n",
    "\n",
    "print(float(a[2]))\n",
    "\n",
    "zeros = torch.zeros(3, 2)\n",
    "print(f'zeros: {zeros}')\n",
    "\n",
    "b = torch.tensor([4.0, 1.0, 5.0, 3.0, 2.0, 1.0])\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "points: tensor([[4., 1.],\n",
      "        [5., 3.],\n",
      "        [2., 1.]])\n",
      "points.shape: torch.Size([3, 2])\n",
      "tensor(1.)\n",
      "tensor([4., 1.])\n"
     ]
    }
   ],
   "source": [
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "print(f'points: {points}')\n",
    "print(f'points.shape: {points.shape}')\n",
    "print(points[0, 1])\n",
    "print(points[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 3.],\n",
      "        [2., 1.]])\n",
      "tensor([[5., 3.],\n",
      "        [2., 1.]])\n",
      "tensor([5., 2.])\n",
      "tensor([[[4., 1.],\n",
      "         [5., 3.],\n",
      "         [2., 1.]]])\n"
     ]
    }
   ],
   "source": [
    "print(points[1:])\n",
    "print(points[1:, :])\n",
    "print(points[1:, 0])\n",
    "print(points[None]) # adds a dimension of size 1 (unsqueeze)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), torch.Size([2, 5, 5]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_t = torch.randn(3, 5, 5) # channels, rows, columns\n",
    "weights = torch.tensor([0.2126, 0.7152, 0.0722])\n",
    "\n",
    "# batch of multiple RGB images\n",
    "batch_t = torch.randn(2, 3, 5, 5) # batch, channels, rows, columns\n",
    "\n",
    "# RGB dimension is always in position -3, to have grayscale remove -3\n",
    "img_gray_naive = img_t.mean(-3)\n",
    "batch_gray_naive = batch_t.mean(-3)\n",
    "img_gray_naive.shape, batch_gray_naive.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1, 1]), torch.Size([3, 5, 5]), torch.Size([2, 3, 5, 5]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unsqueezed_weights = weights.unsqueeze(-1).unsqueeze_(-1)\n",
    "img_weights = img_t * unsqueezed_weights\n",
    "batch_weights = batch_t * unsqueezed_weights\n",
    "img_gray_weighted = img_weights.sum(-3)\n",
    "batch_gray_weighted = batch_weights.sum(-3)\n",
    "\n",
    "unsqueezed_weights.shape, img_weights.shape, batch_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 5]), torch.Size([2, 5, 5]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# einsum una roba strana che permette di fare somme e dare dei nomi agli indici. I ... indicano altri indici senza nome\n",
    "img_gray_weighted_fancy = torch.einsum('...chw,c->...hw', img_t, weights)\n",
    "batch_gray_weighted_fancy = torch.einsum('...chw,c->...hw', batch_t, weights)\n",
    "img_gray_weighted_fancy.shape, batch_gray_weighted_fancy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rabdo\\AppData\\Local\\Temp\\ipykernel_5492\\2371314847.py:1: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1408.)\n",
      "  weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([0.2126, 0.7152, 0.0722], names=('channels',))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_named = torch.tensor([0.2126, 0.7152, 0.0722], names=['channels'])\n",
    "weights_named"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img named: torch.Size([3, 5, 5]) ('channels', 'rows', 'columns')\n",
      "batch named: torch.Size([2, 3, 5, 5]) (None, 'channels', 'rows', 'columns')\n"
     ]
    }
   ],
   "source": [
    "img_named = img_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "batch_named = batch_t.refine_names(..., 'channels', 'rows', 'columns')\n",
    "print(f'img named: {img_named.shape} {img_named.names}')\n",
    "print(f'batch named: {batch_named.shape} {batch_named.names}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0.2126]],\n",
       " \n",
       "         [[0.7152]],\n",
       " \n",
       "         [[0.0722]]], names=('channels', 'rows', 'columns')),\n",
       " torch.Size([3, 1, 1]),\n",
       " ('channels', 'rows', 'columns'))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights_aligned = weights_named.align_as(img_named)\n",
    "weights_aligned, weights_aligned.shape, weights_aligned.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.5248, -0.7616,  0.1509,  0.5471, -0.5278],\n",
       "         [-0.6168, -0.1015, -0.1118, -0.0617,  0.4436],\n",
       "         [ 0.4223, -0.0918,  0.4707, -1.4474, -0.2916],\n",
       "         [-0.4847, -1.0717, -0.6462,  0.5603,  0.5324],\n",
       "         [-0.9986, -0.6881, -0.3101, -0.5665, -1.2249]],\n",
       "        names=('rows', 'columns')),\n",
       " torch.Size([5, 5]),\n",
       " ('rows', 'columns'))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_named = (img_named * weights_aligned).sum('channels')\n",
    "gray_named, gray_named.shape, gray_named.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.5248, -0.7616,  0.1509,  0.5471, -0.5278],\n",
       "         [-0.6168, -0.1015, -0.1118, -0.0617,  0.4436],\n",
       "         [ 0.4223, -0.0918,  0.4707, -1.4474, -0.2916],\n",
       "         [-0.4847, -1.0717, -0.6462,  0.5603,  0.5324],\n",
       "         [-0.9986, -0.6881, -0.3101, -0.5665, -1.2249]]),\n",
       " torch.Size([5, 5]),\n",
       " (None, None))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gray_plain = gray_named.rename(None)\n",
    "gray_plain, gray_plain.shape, gray_plain.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "double: torch.float64 - short: torch.int16\n",
      "double: torch.float64 - short: torch.int16\n",
      "double: torch.float64 - short: torch.int16\n"
     ]
    }
   ],
   "source": [
    "# dtype of tensor items are by default float32 or int64\n",
    "double_points = torch.ones(10, 2, dtype=torch.double)\n",
    "short_points = torch.tensor([[1, 2], [3, 4]], dtype=torch.short)\n",
    "print(f'double: {double_points.dtype} - short: {short_points.dtype}')\n",
    "\n",
    "double_points = torch.zeros(10, 2).double()\n",
    "short_points = torch.ones(4, 5).short()\n",
    "print(f'double: {double_points.dtype} - short: {short_points.dtype}')\n",
    "\n",
    "double_points = torch.zeros(10, 2).to(torch.double)\n",
    "short_points = torch.ones(4, 5).to(torch.short)\n",
    "print(f'double: {double_points.dtype} - short: {short_points.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 2]), torch.Size([2, 3]))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#operations...\n",
    "a = torch.ones(3, 2)\n",
    "a_tran = a.transpose(0, 1) # or torch.transpose(a, 0, 1)\n",
    "a.shape, a_tran.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 4.0\n",
      " 1.0\n",
      " 5.0\n",
      " 3.0\n",
      " 2.0\n",
      " 1.0\n",
      "[torch.storage._TypedStorage(dtype=torch.float32, device=cpu) of size 6]\n",
      "5.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  4., 100.],\n",
       "        [  5.,   3.],\n",
       "        [  2.,   1.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(points.storage())\n",
    "print(points.storage()[2])\n",
    "points.storage()[1] = 100.0\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# operators that end with _ work in place on the tensor changing its content, operators not ending with _ return a new tensor\n",
    "a = torch.ones(3, 2)\n",
    "a.zero_()\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([5., 3.])\n",
      "tensor([[ 4.,  1.],\n",
      "        [10.,  3.],\n",
      "        [ 2.,  1.]])\n",
      "tensor([5., 3.])\n",
      "tensor([[4., 1.],\n",
      "        [5., 3.],\n",
      "        [2., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# a sub-tensor created from an existing tensor share the same storage, using different offset, size and stride. Be careful changing the sub-tensor content change also the original tensor\n",
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_point = points[1]\n",
    "print(second_point)\n",
    "second_point[0] = 10.0\n",
    "print(points)\n",
    "\n",
    "# to avoid changing original tensor, clone\n",
    "points = torch.tensor([[4.0, 1.0], [5.0, 3.0], [2.0, 1.0]])\n",
    "second_point = points[1].clone()\n",
    "print(second_point)\n",
    "second_point[0] = 10.0\n",
    "print(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 1.],\n",
      "        [5., 3.],\n",
      "        [2., 1.]]) (2, 1)\n",
      "tensor([[4., 5., 2.],\n",
      "        [1., 3., 1.]]) (1, 2)\n",
      "tensor([[[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]],\n",
      "\n",
      "        [[1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.],\n",
      "         [1., 1., 1., 1.]]]) (12, 4, 1)\n",
      "tensor([[[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]],\n",
      "\n",
      "        [[1., 1.],\n",
      "         [1., 1.],\n",
      "         [1., 1.]]]) (1, 4, 12)\n",
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(True, False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# transpose is an in-place operation that do not change storage, but only size and stride\n",
    "points_tran = points.t()\n",
    "print(f'{points} {points.stride()}')\n",
    "print(f'{points_tran} {points_tran.stride()}')\n",
    "\n",
    "# multidimensional transpose, choose the 2 dimension to transpose:\n",
    "some_t = torch.ones(2, 3, 4)\n",
    "transpose_t = some_t.transpose(0, 2)\n",
    "print(f'{some_t} {some_t.stride()}')\n",
    "print(f'{transpose_t} {transpose_t.stride()}')\n",
    "\n",
    "print(id(some_t.storage()) == id(transpose_t.storage()))\n",
    "\n",
    "some_t.is_contiguous(), transpose_t.is_contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [18], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m points_gpu \u001b[39m=\u001b[39m points\u001b[39m.\u001b[39;49mto(device\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mcuda\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39m# if more than a GPU is available it can be indexed 'cuda:0'. It's also possible to use points.cuda() or points.cuda(0)\u001b[39;00m\n\u001b[0;32m      2\u001b[0m points_back \u001b[39m=\u001b[39m points_gpu\u001b[39m.\u001b[39mto(device\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\rabdo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\cuda\\__init__.py:211\u001b[0m, in \u001b[0;36m_lazy_init\u001b[1;34m()\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[0;32m    208\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    209\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mmultiprocessing, you must use the \u001b[39m\u001b[39m'\u001b[39m\u001b[39mspawn\u001b[39m\u001b[39m'\u001b[39m\u001b[39m start method\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    210\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(torch\u001b[39m.\u001b[39m_C, \u001b[39m'\u001b[39m\u001b[39m_cuda_getDeviceCount\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m--> 211\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mTorch not compiled with CUDA enabled\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    212\u001b[0m \u001b[39mif\u001b[39;00m _cudart \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    213\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAssertionError\u001b[39;00m(\n\u001b[0;32m    214\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "points_gpu = points.to(device='cuda') # if more than a GPU is available it can be indexed 'cuda:0'. It's also possible to use points.cuda() or points.cuda(0)\n",
    "points_back = points_gpu.to(device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4., 1.],\n",
      "        [5., 3.],\n",
      "        [2., 1.]]) torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4., 1.],\n",
       "       [5., 3.],\n",
       "       [2., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor and NumPy arrays are interoperable. When converted they share same storage (if the tensor is in CPU RAM, otherwise it is copied to CPU)\n",
    "points_np = points.numpy()\n",
    "points = torch.from_numpy(points_np)\n",
    "print(points, points.dtype)\n",
    "points_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 1.],\n",
       "        [5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and load\n",
    "torch.save(points, './points.t')\n",
    "points_load = torch.load('./points.t')\n",
    "points_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 3.],\n",
       "        [2., 1.]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save and load in HDF5 interoperable format\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "f = h5py.File('./points.hdf5', 'w') \n",
    "f.create_dataset('coords', data=points.numpy())\n",
    "f.close()\n",
    "\n",
    "f = h5py.File('./points.hdf5', 'r')\n",
    "dset = f['coords']\n",
    "last_points = torch.from_numpy(dset[-2:])\n",
    "f.close() # invalidate dset\n",
    "last_points"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02d069b80ce8d1405797661061ea8b136c47b884583d5712563c1fdf85261dc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
