{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "t_c = [0.5,  14.0, 15.0, 28.0, 11.0,  8.0,  3.0, -4.0,  6.0, 13.0, 21.0]\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)\n",
    "\n",
    "def model(t_u, w1, w2, b):\n",
    "    return w2 * t_u ** 2 + w1 * t_u + b # this will never fit our data\n",
    "\n",
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, optimizer, params, t_u, t_c):\n",
    "    for epoch in range(1,n_epochs+1):\n",
    "        t_p = model(t_u, *params)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 500 == 0:\n",
    "            print(f'Epoch {epoch}, Loss {float(loss)}')\n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 10.708596229553223\n",
      "Epoch 1000, Loss 8.642083168029785\n",
      "Epoch 1500, Loss 7.1710052490234375\n",
      "Epoch 2000, Loss 6.123476982116699\n",
      "Epoch 2500, Loss 5.377227306365967\n",
      "Epoch 3000, Loss 4.845284938812256\n",
      "Epoch 3500, Loss 4.465787887573242\n",
      "Epoch 4000, Loss 4.194724082946777\n",
      "Epoch 4500, Loss 4.0008015632629395\n",
      "Epoch 5000, Loss 3.8617441654205322\n",
      "Epoch 5500, Loss 3.7617242336273193\n",
      "Epoch 6000, Loss 3.689469337463379\n",
      "Epoch 6500, Loss 3.6369712352752686\n",
      "Epoch 7000, Loss 3.5985281467437744\n",
      "Epoch 7500, Loss 3.5700857639312744\n",
      "Epoch 8000, Loss 3.548757314682007\n",
      "Epoch 8500, Loss 3.532496452331543\n",
      "Epoch 9000, Loss 3.519839286804199\n",
      "Epoch 9500, Loss 3.5097503662109375\n",
      "Epoch 10000, Loss 3.501492500305176\n",
      "Epoch 10500, Loss 3.494537591934204\n",
      "Epoch 11000, Loss 3.4885122776031494\n",
      "Epoch 11500, Loss 3.483152151107788\n",
      "Epoch 12000, Loss 3.478268623352051\n",
      "Epoch 12500, Loss 3.473726749420166\n",
      "Epoch 13000, Loss 3.469430446624756\n",
      "Epoch 13500, Loss 3.465311288833618\n",
      "Epoch 14000, Loss 3.4613211154937744\n",
      "Epoch 14500, Loss 3.457425594329834\n",
      "Epoch 15000, Loss 3.4536004066467285\n",
      "Epoch 15500, Loss 3.449828863143921\n",
      "Epoch 16000, Loss 3.446096897125244\n",
      "Epoch 16500, Loss 3.442396402359009\n",
      "Epoch 17000, Loss 3.4387221336364746\n",
      "Epoch 17500, Loss 3.435067892074585\n",
      "Epoch 18000, Loss 3.4314310550689697\n",
      "Epoch 18500, Loss 3.4278106689453125\n",
      "Epoch 19000, Loss 3.4242029190063477\n",
      "Epoch 19500, Loss 3.4206085205078125\n",
      "Epoch 20000, Loss 3.4170234203338623\n",
      "Epoch 20500, Loss 3.4134514331817627\n",
      "Epoch 21000, Loss 3.4098927974700928\n",
      "Epoch 21500, Loss 3.4063360691070557\n",
      "Epoch 22000, Loss 3.4027974605560303\n",
      "Epoch 22500, Loss 3.399264335632324\n",
      "Epoch 23000, Loss 3.395745277404785\n",
      "Epoch 23500, Loss 3.3922293186187744\n",
      "Epoch 24000, Loss 3.388728380203247\n",
      "Epoch 24500, Loss 3.385237216949463\n",
      "Epoch 25000, Loss 3.3817543983459473\n",
      "Epoch 25500, Loss 3.3782806396484375\n",
      "Epoch 26000, Loss 3.3748109340667725\n",
      "Epoch 26500, Loss 3.371351480484009\n",
      "Epoch 27000, Loss 3.3679094314575195\n",
      "Epoch 27500, Loss 3.364469289779663\n",
      "Epoch 28000, Loss 3.361037254333496\n",
      "Epoch 28500, Loss 3.3576247692108154\n",
      "Epoch 29000, Loss 3.3542160987854004\n",
      "Epoch 29500, Loss 3.3508145809173584\n",
      "Epoch 30000, Loss 3.347430467605591\n",
      "Epoch 30500, Loss 3.344050407409668\n",
      "Epoch 31000, Loss 3.3406777381896973\n",
      "Epoch 31500, Loss 3.337317705154419\n",
      "Epoch 32000, Loss 3.3339684009552\n",
      "Epoch 32500, Loss 3.3306233882904053\n",
      "Epoch 33000, Loss 3.327284336090088\n",
      "Epoch 33500, Loss 3.3239622116088867\n",
      "Epoch 34000, Loss 3.3206450939178467\n",
      "Epoch 34500, Loss 3.317328691482544\n",
      "Epoch 35000, Loss 3.3140265941619873\n",
      "Epoch 35500, Loss 3.3107385635375977\n",
      "Epoch 36000, Loss 3.30745530128479\n",
      "Epoch 36500, Loss 3.304177761077881\n",
      "Epoch 37000, Loss 3.3009157180786133\n",
      "Epoch 37500, Loss 3.2976632118225098\n",
      "Epoch 38000, Loss 3.2944135665893555\n",
      "Epoch 38500, Loss 3.2911691665649414\n",
      "Epoch 39000, Loss 3.287942409515381\n",
      "Epoch 39500, Loss 3.284724235534668\n",
      "Epoch 40000, Loss 3.281510353088379\n",
      "Epoch 40500, Loss 3.2783021926879883\n",
      "Epoch 41000, Loss 3.2751121520996094\n",
      "Epoch 41500, Loss 3.271925926208496\n",
      "Epoch 42000, Loss 3.2687454223632812\n",
      "Epoch 42500, Loss 3.2655744552612305\n",
      "Epoch 43000, Loss 3.2624192237854004\n",
      "Epoch 43500, Loss 3.259263515472412\n",
      "Epoch 44000, Loss 3.256115674972534\n",
      "Epoch 44500, Loss 3.252973794937134\n",
      "Epoch 45000, Loss 3.249833583831787\n",
      "Epoch 45500, Loss 3.246727705001831\n",
      "Epoch 46000, Loss 3.243623971939087\n",
      "Epoch 46500, Loss 3.2405271530151367\n",
      "Epoch 47000, Loss 3.2374353408813477\n",
      "Epoch 47500, Loss 3.2343506813049316\n",
      "Epoch 48000, Loss 3.231266736984253\n",
      "Epoch 48500, Loss 3.2281882762908936\n",
      "Epoch 49000, Loss 3.225118398666382\n",
      "Epoch 49500, Loss 3.2220795154571533\n",
      "Epoch 50000, Loss 3.2190427780151367\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.8635,  0.5856, -2.1345], requires_grad=True)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = torch.tensor([1.0, 1.0, 0.0], requires_grad=True)\n",
    "learning_rate = 1e-4\n",
    "optimizer = optim.SGD([params], lr=learning_rate)\n",
    "\n",
    "t_un = 0.1 * t_u\n",
    "\n",
    "training_loop(n_epochs=50000,\n",
    "              optimizer=optimizer,\n",
    "              params=params,\n",
    "              t_u=t_un,\n",
    "              t_c=t_c)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02d069b80ce8d1405797661061ea8b136c47b884583d5712563c1fdf85261dc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
