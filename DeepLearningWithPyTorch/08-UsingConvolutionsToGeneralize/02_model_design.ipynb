{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "\n",
    "from datetime import datetime as dt\n",
    "\n",
    "# we can improve our model using weight penalties to limit overfitting, we decrease the weight of errors so loss curve is smoother\n",
    "# => there is less to gain from fitting individual samples\n",
    "# we use L2\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "def training_loop_l2reg(n_epochs, optimizer, model, loss_fn, train_loader):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        for imgs, labels in train_loader:\n",
    "            imgs.to(device=device)   # add this\n",
    "            labels.to(device=device) # add this\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_fn(outputs, labels)\n",
    "\n",
    "            l2_lambda = 0.001 # hyper-parameter\n",
    "            l2_norm = sum(p.pow(2.0).sum() for p in model.parameters())\n",
    "            loss = loss + l2_lambda * l2_norm\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_train += loss.item()\n",
    "        \n",
    "        if epoch == 1 or epoch % 10 == 0:\n",
    "            print(f'{dt.now()} Epoch {epoch}, Training loss {loss_train / len(train_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also use dropout to turn off some neurons randomly and do something similar to augmentation but on the network instead of the dataset\n",
    "# dropout is active in training and disabled when predicting => remember to call model.eval() or model.train() to switch modality\n",
    "\n",
    "class NetDropout(nn.Module):\n",
    "    def __init__(self, n_channel=32) -> None:\n",
    "        super().__init__()\n",
    "        self.n_channel = n_channel\n",
    "        self.conv1 = nn.Conv2d(3, n_channel, kernel_size=3, padding=1)\n",
    "        self.conv1_dropout = nn.Dropout2d(p=0.4)\n",
    "        self.conv2 = nn.Conv2d(n_channel, n_channel // 2, kernel_size=3, padding=1)\n",
    "        self.conv2_dropout = nn.Dropout2d(p=0.4)\n",
    "        self.fc1 = nn.Linear(8*8*(n_channel // 2), 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.tanh(self.conv1(x)), 2)\n",
    "        out = self.conv1_dropout(out)\n",
    "        out = F.max_pool2d(torch.tanh(self.conv2(out)), 2)\n",
    "        out = self.conv2_dropout(out)\n",
    "        out = out.view(-1, 8*8*(self.n_channel // 2))\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or use batch normalization that compute normalization on batches\n",
    "\n",
    "class NetBatchNorm(nn.Module):\n",
    "    def __init__(self, n_channel=32) -> None:\n",
    "        super().__init__()\n",
    "        self.n_channel = n_channel\n",
    "        self.conv1 = nn.Conv2d(3, n_channel, kernel_size=3, padding=1)\n",
    "        self.conv1_batchnorm = nn.BatchNorm2d(num_features=n_channel)\n",
    "        self.conv2 = nn.Conv2d(n_channel, n_channel // 2, kernel_size=3, padding=1)\n",
    "        self.conv2_batchnorm = nn.BatchNorm2d(num_features=n_channel // 2)\n",
    "        self.fc1 = nn.Linear(8*8*(n_channel // 2), 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1_batchnorm(self.conv1(x))\n",
    "        out = F.max_pool2d(torch.tanh(out), 2)\n",
    "        out = self.conv2_batchnorm(self.conv2(x))\n",
    "        out = F.max_pool2d(torch.tanh(out), 2)\n",
    "        out = self.conv2_dropout(out)\n",
    "        out = out.view(-1, 8*8*(self.n_channel // 2))\n",
    "        out = torch.tanh(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or increase network depth...but deep network do a lot of operations in series and then gradients of deeper layers tend to disappear and not be updated\n",
    "# ResNet solved this issue adding \"skip connections\" connect directly inputs to outputs of a layer:\n",
    "\n",
    "class NetRes(nn.Module):\n",
    "    def __init__(self, n_channel=32) -> None:\n",
    "        super().__init__()\n",
    "        self.n_channel = n_channel\n",
    "        self.conv1 = nn.Conv2d(3, n_channel, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(n_channel, n_channel // 2, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(n_channel // 2, n_channel // 2, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(8*8*(n_channel // 2), 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = F.max_pool2d(torch.relu(self.conv2(out)), 2)\n",
    "        out1 = out\n",
    "        out = F.max_pool2d(torch.relu(self.conv3(out)) + out1, 2) # skip connection\n",
    "        out = out.view(-1, 4*4*(self.n_channel // 2))\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how to write a really deep (>100 layer) network in pytorch?\n",
    "\n",
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, n_channel) -> None:\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(n_channel, n_channel, kernel_size=3, padding=True, bias=False) # bias would be neutralized by batch norm\n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=n_channel)\n",
    "        torch.nn.init.kaiming_normal_(self.conv.weight, nonlinearity='relu') # initialize random parameters as done in ResNet paper\n",
    "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
    "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv(x)\n",
    "        out = self.batch_norm(out)\n",
    "        out = torch.relu(out)\n",
    "        return out + x\n",
    "\n",
    "class NetResDeep(nn.Module):\n",
    "    def __init__(self, n_channel=32, n_blocks=10) -> None:\n",
    "        super().__init__()\n",
    "        self.n_channel = n_channel\n",
    "        self.conv1 = nn.Conv2d(3, n_channel, kernel_size=3, padding=True)\n",
    "        self.resblocks = nn.Sequential(*(n_blocks * [ResBlock(n_channel=n_channel)]))\n",
    "        self.fc1 = nn.Linear(8*8*n_channel, 32)\n",
    "        self.fc2 = nn.Linear(32, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
    "        out = self.resblocks(out)\n",
    "        out = F.max_pool2d(out, 2)\n",
    "        out = out.view(-1, 8*8*(self.n_channel // 2))\n",
    "        out = torch.relu(self.fc1(out))\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "02d069b80ce8d1405797661061ea8b136c47b884583d5712563c1fdf85261dc1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
